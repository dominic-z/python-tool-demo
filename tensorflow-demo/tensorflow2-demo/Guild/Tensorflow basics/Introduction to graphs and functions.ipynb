{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Python function\n",
    "def function_to_get_faster(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Create a `Function` object that contains a graph\n",
    "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\n",
    "\n",
    "# Make some tensors\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "# It just works!\n",
    "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes inner_function() as well as outer_function()\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1.0\n",
      "Second branch, with graph: [4. 4.]\n"
     ]
    }
   ],
   "source": [
    "def my_function(x):\n",
    "  if tf.reduce_sum(x) <= 1:\n",
    "    return x * x\n",
    "  else:\n",
    "    return x-1\n",
    "\n",
    "a_function = tf.function(my_function)\n",
    "\n",
    "print(\"First branch, with graph:\", a_function(tf.constant(1.0)).numpy())\n",
    "print(\"Second branch, with graph:\", a_function(tf.constant([5.0, 5.0])).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__my_function(x):\n",
      "    with ag__.FunctionScope('my_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal do_return, retval_\n",
      "            (do_return, retval_) = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = (ag__.ld(x) * ag__.ld(x))\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = (ag__.ld(x) - 1)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt((ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(x),), None, fscope) <= 1), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Don't read the output too carefully.\n",
    "print(tf.autograph.to_code(my_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager time: 5.0723486938513815\n",
      "Graph time: 2.7211625669151545\n"
     ]
    }
   ],
   "source": [
    "# Create an oveerride model to classify pictures\n",
    "class SequentialModel(tf.keras.Model):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(SequentialModel, self).__init__(**kwargs)\n",
    "    self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "    self.dense_1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.dense_2 = tf.keras.layers.Dense(10)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.dense_2(x)\n",
    "    return x\n",
    "\n",
    "input_data = tf.random.uniform([60, 28, 28])\n",
    "\n",
    "eager_model = SequentialModel()\n",
    "graph_model = tf.function(eager_model)\n",
    "\n",
    "print(\"Eager time:\", timeit.timeit(lambda: eager_model(input_data), number=10000))\n",
    "print(\"Graph time:\", timeit.timeit(lambda: graph_model(input_data), number=10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.def_function.Function object at 0x7f0a1453acf8>\n",
      "Calling a `Function`:\n",
      "Int: tf.Tensor(1, shape=(), dtype=int32)\n",
      "Float: tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Rank-1 tensor of floats tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a_function)\n",
    "\n",
    "print(\"Calling a `Function`:\")\n",
    "print(\"Int:\", a_function(tf.constant(2)))\n",
    "print(\"Float:\", a_function(tf.constant(2.0)))\n",
    "print(\"Rank-1 tensor of floats\", a_function(tf.constant([2.0, 2.0, 2.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting concrete functions\n",
      "Concrete function for float:\n",
      "ConcreteFunction my_function(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "Concrete function for tensor of floats:\n",
      "ConcreteFunction my_function(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(3,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(3,)\n"
     ]
    }
   ],
   "source": [
    "# Get the concrete function that works on floats\n",
    "print(\"Inspecting concrete functions\")\n",
    "print(\"Concrete function for float:\")\n",
    "print(a_function.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.float32)))\n",
    "print(\"Concrete function for tensor of floats:\")\n",
    "print(a_function.get_concrete_function(tf.constant([2.0, 2.0, 2.0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directly calling a concrete function: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Concrete functions are callable\n",
    "# Note: You won't normally do this, but instead just call the containing `Function`\n",
    "cf = a_function.get_concrete_function(tf.constant(2))\n",
    "print(\"Directly calling a concrete function:\", cf(tf.constant(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define an identity layer with an eager side effect\n",
    "class EagerLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super(EagerLayer, self).__init__(**kwargs)\n",
    "    # Do some kind of initialization here\n",
    "\n",
    "  def call(self, inputs):\n",
    "    print(\"\\nCurrently running eagerly\", str(datetime.now()))\n",
    "    return inputs\n",
    "\n",
    "# Create an override model to classify pictures, adding the custom layer\n",
    "class SequentialModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(SequentialModel, self).__init__()\n",
    "    self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "    self.dense_1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.dense_2 = tf.keras.layers.Dense(10)\n",
    "    self.eager = EagerLayer()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.dense_2(x)\n",
    "    return self.eager(x)\n",
    "\n",
    "# Create an instance of this model\n",
    "model = SequentialModel()\n",
    "\n",
    "# Generate some nonsense pictures and labels\n",
    "input_data = tf.random.uniform([60, 28, 28])\n",
    "labels = tf.random.uniform([60])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(run_eagerly=False, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:10:30.720751\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:10:30.804063\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0498\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09a01c40f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_data, labels, epochs=3)\n",
    "# 为啥有两次trace，我就不清楚了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running eagerly\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:10:44.247480\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0027\n",
      "Currently running eagerly 2020-10-05 08:10:44.261138\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09a0317be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Running eagerly\")\n",
    "# When compiling the model, set it to run eagerly\n",
    "model.compile(run_eagerly=True, loss=loss_fn)\n",
    "\n",
    "model.fit(input_data, labels, epochs=1)\n",
    "# 一个epoch也会触发两次运算，不知为啥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently running eagerly 2020-10-05 08:12:15.821909\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:12:15.822113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eager_layer=EagerLayer()\n",
    "eager_layer(1)\n",
    "eager_layer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run all functions eagerly.\n",
      "Tracing\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:16:24.609254\n",
      "ConcreteFunction function(self)\n",
      "  Args:\n",
      "    self: float32 Tensor, shape=(60, 28, 28)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(60, 10)\n",
      "\n",
      "Calling twice eagerly\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:16:24.613181\n",
      "\n",
      "Currently running eagerly 2020-10-05 08:16:24.614320\n"
     ]
    }
   ],
   "source": [
    "# Now, globally set everything to run eagerly\n",
    "tf.config.run_functions_eagerly(True)\n",
    "print(\"Run all functions eagerly.\")\n",
    "\n",
    "# Create a polymorphic function\n",
    "polymorphic_function = tf.function(model)\n",
    "\n",
    "print(\"Tracing\")\n",
    "# This does, in fact, trace the function\n",
    "print(polymorphic_function.get_concrete_function(input_data))\n",
    "\n",
    "print(\"\\nCalling twice eagerly\")\n",
    "# When you run the function again, you will see the side effect\n",
    "# twice, as the function is running eagerly.\n",
    "result = polymorphic_function(input_data)\n",
    "result = polymorphic_function(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Use @tf.function decorator\n",
    "# tf.config.run_functions_eagerly(False)\n",
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "  print(\"Tracing!\")  # This eager\n",
    "  return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "# The second time through, you won't see the side effect\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))\n",
    "\n",
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))\n",
    "\n",
    "# 不会再tracing，因为之前接收过这种类型的输入，已经trace过了\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace，直面翻译是追踪，功能是由python的动态类型方法转换成graph里的静态类型方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
