{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ds: <TensorSliceDataset shapes: (2, 3), types: tf.int32>\n",
      "==================\n",
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 1 23  3]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  2   3   4]\n",
      " [ 12 233  13]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  2   3   4]\n",
      " [ 12 233  13]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  2   3   4]\n",
      " [ 12 233  13]], shape=(2, 3), dtype=int32)\n",
      "==================\n",
      "<BatchDataset shapes: (None, 2, 3), types: tf.int32>\n",
      "==================\n",
      "tf.Tensor(\n",
      "[[[  1   2   3]\n",
      "  [  1  23   3]]\n",
      "\n",
      " [[  2   3   4]\n",
      "  [ 12 233  13]]], shape=(2, 2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[  2   3   4]\n",
      "  [ 12 233  13]]\n",
      "\n",
      " [[  2   3   4]\n",
      "  [ 12 233  13]]], shape=(2, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 可以把dataset看做一个java里的列表容器对象，其中的shapes指的就是这个ds持有的每一个对象的shape\n",
    "# 在这个例子里，传入的是一个列表，这个列表里每一个元素都是2*3的数组\n",
    "test_ds=tf.data.Dataset.from_tensor_slices([[[1,2,3],[1,23,3]],\n",
    "                                            [[2,3,4],[12,233,13]],\n",
    "                                            [[2,3,4],[12,233,13]],\n",
    "                                            [[2,3,4],[12,233,13]]])\n",
    "print(\"test ds:\",test_ds)\n",
    "\n",
    "print(\"==================\")\n",
    "for row in test_ds:\n",
    "  print(row)\n",
    "\n",
    "print(\"==================\")\n",
    "print(test_ds.batch(2))\n",
    "print(\"==================\")\n",
    "for b in test_ds.batch(2):\n",
    "  print(b)\n",
    "\n",
    "# test_ds 原本的形状是(2,3)，里面持有多少个元素暂时不知道\n",
    "# batch之后，会把两个元素打包成1个batch，得到了一个BatchDataset shapes: (None, 2, 3)\n",
    "# 这个None实际上代表的就是那个2，我猜tensorflow由于懒加载机制，所以暂时这个产生的batchdataset不知道具体的batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((3,), (2, 2)), types: (tf.int32, tf.int32)>\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [1, 2]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([4, 5, 6], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
      "array([[4, 5],\n",
      "       [6, 7]], dtype=int32)>)\n",
      "================\n",
      "<TensorSliceDataset shapes: (), types: tf.float32>\n",
      "=========================\n",
      "<MapDataset shapes: ((), ()), types: (tf.float32, tf.float32)>\n",
      "=========================\n",
      "<BatchDataset shapes: ((None,), (None,)), types: (tf.float32, tf.float32)>\n",
      "=========================\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.5, 2.5, 3.5], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.5], dtype=float32)>)\n",
      "=========================\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: shape=(), dtype=float32, numpy=1.5>)\n"
     ]
    }
   ],
   "source": [
    "# 如何让dataset同时持有多个list，答案就是使用tuple\n",
    "# 下面这个例子里，这个dataset通过tuple，持有了多个list\n",
    "test_ds=tf.data.Dataset.from_tensor_slices(([[1,2,3],[4,5,6]],\n",
    "                                            [[[1,2],[1,2]],\n",
    "                                             [[4,5],[6,7]]]))\n",
    "# 通过按顺序打印结果发现，这个dataset里的第一个item，是第一个列表的第一个元素与第二个列表的第一个元素组成的tuple\n",
    "# 第二个item是第一个列表的第二个元素与第二个列表的第二个元素组成的tuple\n",
    "# 进而可以得知，输入的各个列表的第0轴的维度应该相同\n",
    "print(test_ds)\n",
    "for item in test_ds:\n",
    "  print(item)\n",
    "\n",
    "print(\"================\")\n",
    "test_ds=tf.data.Dataset.from_tensor_slices(\n",
    "  [tf.constant(1.),tf.constant(2.),\n",
    "   tf.constant(3.),tf.constant(4.)])\n",
    "print(test_ds)\n",
    "print(\"=========================\")\n",
    "tuple_ds=test_ds.map(lambda i:(i,tf.add(i,0.5)))\n",
    "print(tuple_ds)\n",
    "# 这样就获得了一个持有元素为tuple，并且每个tuple里的形状是((),())，即俩数的tuple\n",
    "# 也就是[(1,1.5),(2,2.5),(3,3.5),(4,4.5)]\n",
    "print(\"=========================\")\n",
    "batch_ds=tuple_ds.batch(3)\n",
    "print(batch_ds)\n",
    "print(\"=========================\")\n",
    "for b in batch_ds:\n",
    "  print(b)\n",
    "# 注意，这种情况下，由于tuple_ds持有的是多个list，\n",
    "# 所以对这类对象进行batch的时候，是对所有的list进行batch\n",
    "# 通过观察batch_ds的形状可知，他是对每个tuple的相同位置的数字进行了batch\n",
    "# 所以生成的是BatchDataset shapes: ((None,), (None,))这种形状的\n",
    "# 也就是这个batch持有的仍然是多个list，但是其中的每个元素不再是一个数字了\n",
    "# 而是batch_size大小的列表，也就是([[1,2,3],[1.5,2.5,3.5]],[[4],[4.5]])\n",
    "\n",
    "print(\"=========================\")\n",
    "for b in tuple_ds.take(1):\n",
    "  print(b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<MapDataset shapes: (), types: tf.int32>\n",
      "<MapDataset shapes: (1,), types: tf.int8>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes at component 0: expected [1] but got [].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0mTraceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36mexecution_mode\u001B[0;34m(mode)\u001B[0m\n\u001B[1;32m   2101\u001B[0m       \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecutor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexecutor_new\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2102\u001B[0;31m       \u001B[0;32myield\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2103\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001B[0m in \u001B[0;36m_next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    757\u001B[0m             \u001B[0moutput_types\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_flat_output_types\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 758\u001B[0;31m             output_shapes=self._flat_output_shapes)\n\u001B[0m\u001B[1;32m    759\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001B[0m in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   2609\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2610\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2611\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6842\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6843\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6844\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Incompatible shapes at component 0: expected [1] but got []. [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0mTraceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-3857ec8aea94>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_ds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_ds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_ds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    735\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# For Python 3 compatibility\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 736\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    737\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    738\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_next_internal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001B[0m in \u001B[0;36mnext\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    770\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    771\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 772\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_internal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    773\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    774\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001B[0m in \u001B[0;36m_next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    762\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_element_spec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_from_compatible_tensor_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mret\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    763\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 764\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_compatible_tensor_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_element_spec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    765\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    766\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.6/contextlib.py\u001B[0m in \u001B[0;36m__exit__\u001B[0;34m(self, type, value, traceback)\u001B[0m\n\u001B[1;32m     97\u001B[0m                 \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mthrow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m                 \u001B[0;31m# Suppress StopIteration *unless* it's the same exception that\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001B[0m in \u001B[0;36mexecution_mode\u001B[0;34m(mode)\u001B[0m\n\u001B[1;32m   2103\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2104\u001B[0m       \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecutor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexecutor_old\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2105\u001B[0;31m       \u001B[0mexecutor_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     65\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m     \u001B[0mpywrap_tfe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTFE_ExecutorWaitForAllPendingNodes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mclear_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Incompatible shapes at component 0: expected [1] but got []."
     ]
    }
   ],
   "source": [
    "#py_function与map\n",
    "\n",
    "\"\"\"\n",
    "https://www.tensorflow.org/tutorials/load_data/text\n",
    "You want to use Dataset.map to apply this function to each element of the dataset. Dataset.map runs in graph mode.\n",
    "Graph tensors do not have a value.\n",
    "In graph mode you can only use TensorFlow Ops and functions.\n",
    "So you can't .map this function directly: You need to wrap it in a tf.py_function. The tf.py_function will pass regular tensors (with a value and a .numpy() method to access it), to the wrapped python function.\n",
    "\"\"\"\n",
    "\n",
    "test_ds=tf.data.Dataset.range(1,10)\n",
    "# print(test_ds)\n",
    "def py_function(tensor):\n",
    "  print(type(tensor)) #这一句函数只会在next(iter(test_ds.map(op).take(1)))真正地执行，理解这个很重要\n",
    "  # 而且类型是tensorflow.python.framework.ops.EagerTensor\n",
    "  return tensor.numpy()+1\n",
    "\n",
    "def show(tensor):\n",
    "  print(type(tensor))\n",
    "  # Tensor(\"args_0:0\", shape=(), dtype=int64)\n",
    "  # 可以看出这个tensor是没有值的，这是一个graph的tensor。没法取出相应的值\n",
    "  # 个人理解\n",
    "  # 最重要的点是，这个map也是一个op，并不是实际的计算\n",
    "  # 如果对map输入了这个show，相当于在graph上放置了一个op，放置这个操作会触发这个show执行\n",
    "  # 所以上面的这个print方法会在放置的时候执行\n",
    "  # 而此时，在这个graph里，这个op只知道这个tensor的类型（基于dataset但注意dataset也是不知道具体的数据的）\n",
    "  # 这个tensor指的就是只是指向某个数据的张量\n",
    "  # 所以没法去执行numpy()\n",
    "  return 1\n",
    "\n",
    "def op(tensor):\n",
    "  # py_function可以在运行时将graph tensor转化成常规的tensor\n",
    "  res=tf.py_function(py_function,\n",
    "                     inp=[tensor],\n",
    "                     Tout=tf.int8)\n",
    "  res.set_shape([])#由于这个方法被用在map阶段，所以最好还是设置好tensor的形状，以便后续的方法操作\n",
    "  return res\n",
    "\n",
    "print(test_ds.map(show))\n",
    "print(test_ds.map(op))\n",
    "# 在take阶段，真正地出发了op的执行\n",
    "print(next(iter(test_ds.map(op).take(1))))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"==========================\")\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "def get_dict(i):\n",
    "  d=OrderedDict()\n",
    "  d[\"a\"]=tf.cast(i,tf.float32)\n",
    "  d[\"b\"]=np.random.normal()\n",
    "  return (d,i)\n",
    "\n",
    "test_ds=tf.data.Dataset.range(1,4).map(lambda x:get_dict(x))\n",
    "print(test_ds)\n",
    "\n",
    "def pack(features, label):\n",
    "  print(\"print once only\",features)# 可以看到这个feature直接就是order dict，他的values才是tensor，所以不用挂py_function\n",
    "  values=list(features.values())\n",
    "  return tf.add(values,1.1),label\n",
    "packed_dataset = test_ds.map(pack)\n",
    "\n",
    "# 所以说，map的时候，pack函数就会执行，但实际上只会执行一次，但这个执行并不是真正意义上的计算，本质是将一个op放在graph上。\n",
    "# 所以对张量取值是取不到的\n",
    "# 所以什么时候需要包py_function呢，只要涉及对tensor的具体值的处理，就需要包\n",
    "# 但就像这个例子里，temp_dataset里持有的是orderdict，并不是tensor，所以不用包\n",
    "# 再例如如果一个dataset里持有的是tuple，只要不涉及对tensor具体值的处理，也不用包\n",
    "# 就像ds.map(lambda x,y:(1,2))，你看，这也不用py_function\n",
    "for features, labels in packed_dataset.take(1):\n",
    "  print(features.numpy())\n",
    "  print()\n",
    "  print(labels.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'A_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'A_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'A_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'A_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'B_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'B_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'B_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'B_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'B_class'>, <tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 1], dtype=int32)>)\n",
      "exec\n"
     ]
    },
    {
     "data": {
      "text/plain": "<MapDataset shapes: ((), (2,)), types: (tf.string, tf.int32)>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset=tf.data.Dataset.range(1,10)\n",
    "def map_func(x):\n",
    "  print(\"exec\")\n",
    "  if tf.less(x,5):\n",
    "    return \"A_class\",[1,0]\n",
    "  return \"B_class\",[0,1]\n",
    "\n",
    "for x in dataset.map(map_func): # 仅仅在map处进行了map操作\n",
    "  print(x)\n",
    "dataset.map(map_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([0 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([0 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 处理SparseTensor\n",
    "import tensorflow as tf\n",
    "test_ds=tf.data.Dataset.from_tensor_slices([\"1:1 2:3;4\",\"1:2 2:5\"])\n",
    "def input_parser(line):\n",
    "    res=tf.sparse.SparseTensor(indices=[[0,1],[1,2]],values=[0,2],dense_shape=[2,2])\n",
    "    return res\n",
    "\n",
    "parsed_ds=test_ds.map(input_parser)\n",
    "\n",
    "for row in parsed_ds:\n",
    "    print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1 2:3;4 3:6\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'1'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'3;4'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'6'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "new row\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'1'>, <tf.Tensor: shape=(), dtype=string, numpy=b'3;4'>, <tf.Tensor: shape=(), dtype=string, numpy=b'6'>)\n",
      "1:2 2:5 3:7\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'2'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'5'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'7'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "new row\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'2'>, <tf.Tensor: shape=(), dtype=string, numpy=b'5'>, <tf.Tensor: shape=(), dtype=string, numpy=b'7'>)\n",
      "1:1 2:4 3:7\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'1'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'4'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'7'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "new row\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'1'>, <tf.Tensor: shape=(), dtype=string, numpy=b'4'>, <tf.Tensor: shape=(), dtype=string, numpy=b'7'>)\n",
      "1:1 2:3;4 3:6\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'1'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'3;4'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'6'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "1:2 2:5 3:7\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'2'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'5'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'7'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "1:1 2:4 3:7new batch\n",
      "(<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'1', b'2'], dtype=object)>, <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'3;4', b'5'], dtype=object)>, <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'6', b'7'], dtype=object)>)\n",
      "\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'1' b'1'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(1, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'2' b'4'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(2, shape=(), dtype=int64)\n",
      "field_feature SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'3' b'7'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64))\n",
      "field_id tf.Tensor(3, shape=(), dtype=int64)\n",
      "new batch\n",
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'7'], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "num_fields=3\n",
    "num_features=8\n",
    "\n",
    "# 处理multihot的样本，输入的是格式是string field_id:feature_id1;feature_id2\n",
    "# 希望的输出是num_fields个shape为[]的string，例如[\"1\",\"3;4\"]\n",
    "# 由于需要具体的取值，因此需要借助py_function对结果进行截断与搜集\n",
    "# map返回的一定是一个tensor，而不能是list之类的对象。因为tensorflow是图计算模式的，python代码的map只会执行一次，而真正执行的是底层的图计算\n",
    "# 注意featureId一定要从0开始，否则转稀疏矩阵时会丢到该值\n",
    "\n",
    "import tensorflow as tf\n",
    "test_ds=tf.data.Dataset.from_tensor_slices([\"1:1 2:3;4 3:6\",\"1:2 2:5 3:7\",\"1:1 2:4 3:7\"])\n",
    "\n",
    "def input_parser_func(line_tensor):\n",
    "    # 返回1 3;4这种数据\n",
    "    real_line=line_tensor\n",
    "    # 将line.numpy转换为string类型更便于处理一些，但是本例中还是使用了tf提供的api直接处理二进制字符串\n",
    "    print(str(real_line.numpy(), encoding = \"utf-8\"))\n",
    "\n",
    "    row=tf.strings.split(real_line,\" \")\n",
    "\n",
    "    feature_strs=list()\n",
    "    for item in row:\n",
    "        field_feature=tf.strings.split([item],\":\").to_sparse()\n",
    "        print(\"field_feature\",field_feature)\n",
    "        field_id=tf.strings.to_number(field_feature.values[0], tf.int64)\n",
    "        print(\"field_id\",field_id)\n",
    "        feature_strs.append(field_feature.values[1])\n",
    "    return feature_strs\n",
    "\n",
    "def input_parser(line):\n",
    "    \"\"\"\n",
    "\n",
    "    :param line: tensor in string\n",
    "    :return: 返回的是一个list，每个元素都是一个field的feature_id字符串，用;连接\n",
    "         希望的输出是num_fields个shape为[]的string，例如[\"1\",\"3;4\"]\n",
    "         注意由于使用了py_function，此处返回的是一个列表，这个列表里有num_fields个tensor，而不是一个shape为[num_fields]的tensor\n",
    "         如果不使用py_function是可以实现后者的，见tensorflow1中的实现\n",
    "    \"\"\"\n",
    "    py_res=tf.py_function(func=input_parser_func,inp=[line],Tout=[tf.string]*num_fields)\n",
    "\n",
    "    return py_res\n",
    "\n",
    "parsed_ds=test_ds.map(input_parser) # 每个item都是num_fields个shape为[]的string\n",
    "# print(parsed_ds)\n",
    "for row in parsed_ds:\n",
    "    print(\"new row\")\n",
    "    print(row)\n",
    "\n",
    "batched_ds=parsed_ds.batch(2) # 每个item都是: field_size个 [batch_size,] 的string\n",
    "# print(batched_ds)\n",
    "\n",
    "for row in batched_ds:\n",
    "    print(\"new batch\")\n",
    "    print(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'1'], [b'2']]>\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 0]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int64), dense_shape=tf.Tensor([2 1], shape=(2,), dtype=int64))\n",
      "<tf.RaggedTensor [[b'3', b'4'], [b'5']]>\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]], shape=(3, 2), dtype=int64), values=tf.Tensor([3 4 5], shape=(3,), dtype=int64), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\n",
      "<tf.RaggedTensor [[b'6'], [b'7']]>\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 0]], shape=(2, 2), dtype=int64), values=tf.Tensor([6 7], shape=(2,), dtype=int64), dense_shape=tf.Tensor([2 1], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[[-0.02719916 -0.7736385   0.00539994  0.15242586]\n",
      "  [ 0.7670817   0.9565993   0.4649043  -0.3597867 ]\n",
      "  [ 0.9922279   1.4511844   0.34339067  0.22595775]]\n",
      "\n",
      " [[ 0.07129501  0.58460325  0.44938353  0.91817623]\n",
      "  [ 1.0877714  -1.2422072   0.0800534   0.48739117]\n",
      "  [-0.4828232  -1.5605565  -0.00997701  0.01435741]]], shape=(2, 3, 4), dtype=float32)\n",
      "<tf.RaggedTensor [[b'1']]>\n",
      "SparseTensor(indices=tf.Tensor([[0 0]], shape=(1, 2), dtype=int64), values=tf.Tensor([1], shape=(1,), dtype=int64), dense_shape=tf.Tensor([1 1], shape=(2,), dtype=int64))\n",
      "<tf.RaggedTensor [[b'4']]>\n",
      "SparseTensor(indices=tf.Tensor([[0 0]], shape=(1, 2), dtype=int64), values=tf.Tensor([4], shape=(1,), dtype=int64), dense_shape=tf.Tensor([1 1], shape=(2,), dtype=int64))\n",
      "<tf.RaggedTensor [[b'7']]>\n",
      "SparseTensor(indices=tf.Tensor([[0 0]], shape=(1, 2), dtype=int64), values=tf.Tensor([7], shape=(1,), dtype=int64), dense_shape=tf.Tensor([1 1], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[[-0.02719916 -0.7736385   0.00539994  0.15242586]\n",
      "  [ 0.09295921  1.8054378   1.1218755  -1.0005178 ]\n",
      "  [-0.4828232  -1.5605565  -0.00997701  0.01435741]]], shape=(1, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_param=tf.random.truncated_normal(shape=(num_features,4))\n",
    "\n",
    "def embedding_layer(batched):\n",
    "    # num_fields个[batch_size,]的str\n",
    "\n",
    "    embs=list()\n",
    "    for i in range(num_fields):\n",
    "\n",
    "        field_i_str=batched[i]\n",
    "        # print(\"field_{}_str\".format(i))\n",
    "        # print(field_i_str)\n",
    "\n",
    "        field_i_strs=tf.strings.split(field_i_str,\";\") # RaggedTensor\n",
    "        # print(\"field_{}_strs\".format(i))\n",
    "        # print(field_i_strs)\n",
    "\n",
    "        field_i=tf.strings.to_number(field_i_strs,tf.int64).to_sparse() # tf2之中可以对RaggedTensor直接调用to_number\n",
    "        # print(\"field_{}\".format(i))\n",
    "        # print(field_i)\n",
    "        sparse_tensor=tf.SparseTensor(indices=field_i.indices,values=field_i.values,dense_shape=field_i.dense_shape)\n",
    "        field_i_emb=tf.nn.embedding_lookup_sparse(params=embedding_param,sp_ids=field_i,sp_weights=None)\n",
    "        embs.append(field_i_emb)\n",
    "\n",
    "    emb=tf.stack(embs,axis=1)\n",
    "    print(emb)\n",
    "\n",
    "\n",
    "for batch in batched_ds:\n",
    "    embedding_layer(batch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}