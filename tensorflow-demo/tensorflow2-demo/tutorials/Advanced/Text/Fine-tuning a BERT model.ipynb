{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n",
      "\u001B[31mERROR: google-api-core 1.22.3 has requirement google-auth<2.0dev,>=1.21.1, but you'll have google-auth 1.19.2 which is incompatible.\u001B[0m\n",
      "\u001B[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tf-nightly\n",
    "!pip install -q tf-models-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_config.json',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_model.ckpt.index',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\n",
    "tf.io.gfile.listdir(gs_folder_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue, info = tfds.load('glue/mrpc', with_info=True,\n",
    "#                        # It's small, load the whole dataset\n",
    "#                        batch_size=-1)\n",
    "\n",
    "my_glue_train={\n",
    "    \"sentence1\":[\n",
    "        tf.constant(\"The identical rovers will act as robotic geologists , searching for evidence of past water .\"),\n",
    "        tf.constant(\"one kitty is cute\")\n",
    "    ],\n",
    "    \"sentence2\":[\n",
    "        tf.constant(\"The rovers act as robotic geologists , moving on six wheels .\"),\n",
    "        tf.constant(\"a little cat is pretty\")\n",
    "    ],\n",
    "    \"label\":tf.constant([0,1]),\n",
    "}\n",
    "# 数据下载不下来，手动造了一个格式差不多的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: b'The identical rovers will act as robotic geologists , searching for evidence of past water .'\n",
      "sentence2: b'The rovers act as robotic geologists , moving on six wheels .'\n",
      "label    : 0\n"
     ]
    }
   ],
   "source": [
    "# glue_train = glue['train']\n",
    "\n",
    "for key, value in my_glue_train.items():\n",
    "  print(f\"{key:9s}: {value[0].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Set up tokenizer to generate Tensorflow dataset\n",
    "tokenizer = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
    "     do_lower_case=True)\n",
    "\n",
    "print(\"Vocab size:\", len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'tensor', '##flow', '!']\n",
      "[7592, 23435, 12314, 999]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"Hello TensorFlow!\")\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 102]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = tf.ones_like([[0,10,1,0],[1,0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "   tokens = list(tokenizer.tokenize(s.numpy()))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# 因为传入的列表的长短不同，因此需要用tf.ragged.constant来转化成tensor\n",
    "sentence1 = tf.ragged.constant([\n",
    "    encode_sentence(s) for s in my_glue_train[\"sentence1\"]])\n",
    "sentence2 = tf.ragged.constant([\n",
    "    encode_sentence(s) for s in my_glue_train[\"sentence2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_values': <tf.Tensor: shape=(23,), dtype=int32, numpy=\n",
       " array([ 1996,  7235,  9819,  2097,  2552,  2004, 20478, 21334,  2015,\n",
       "         1010,  6575,  2005,  3350,  1997,  2627,  2300,  1012,   102,\n",
       "         2028, 14433,  2003, 10140,   102], dtype=int32)>,\n",
       " '_row_partition': tf.RowPartition(row_splits=tf.Tensor([ 0 18 23], shape=(3,), dtype=int64))}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1 shape: [2, None]\n",
      "Sentence2 shape: [2, None]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence1 shape:\", sentence1.shape.as_list())\n",
    "print(\"Sentence2 shape:\", sentence2.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "_ = plt.pcolormesh(input_word_ids.to_tensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[101, 1996, 7235, 9819, 2097, 2552, 2004, 20478, 21334, 2015, 1010, 6575, 2005, 3350, 1997, 2627, 2300, 1012, 102, 1996, 9819, 2552, 2004, 20478, 21334, 2015, 1010, 3048, 2006, 2416, 7787, 1012, 102], [101, 2028, 14433, 2003, 10140, 102, 1037, 2210, 4937, 2003, 3492, 102]]>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f13cb782c50>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_mask = tf.ones_like(input_word_ids).to_tensor() # tf.ones_like(input_word_ids)会返回一个ragedtensor，to tensor就会返回补0之后的tensor对象\n",
    "\n",
    "plt.pcolormesh(input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones_like(input_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 就是拼接操作，0的部分是sentence1，1的部分是sentence2\n",
    "type_cls = tf.zeros_like(cls)\n",
    "type_s1 = tf.zeros_like(sentence1)\n",
    "type_s2 = tf.ones_like(sentence2)\n",
    "input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "\n",
    "input_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(s.numpy())) # 改动\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def bert_encode(glue_dict, tokenizer):\n",
    "  num_examples = len(glue_dict[\"sentence1\"])\n",
    "  \n",
    "  sentence1 = tf.ragged.constant([\n",
    "      encode_sentence(s, tokenizer)\n",
    "      for s in glue_dict[\"sentence1\"]]) # 改动\n",
    "  sentence2 = tf.ragged.constant([\n",
    "      encode_sentence(s, tokenizer)\n",
    "       for s in glue_dict[\"sentence2\"]]) # 改动\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor() # 利用这个to_tensor来补充0\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_s1 = tf.zeros_like(sentence1)\n",
    "  type_s2 = tf.ones_like(sentence2)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids}\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_train = bert_encode(my_glue_train, tokenizer)\n",
    "glue_train_labels = my_glue_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[  101,  1996,  7235,  9819,  2097,  2552,  2004, 20478, 21334,\n",
       "          2015,  1010,  6575,  2005,  3350,  1997,  2627,  2300,  1012,\n",
       "           102,  1996,  9819,  2552,  2004, 20478, 21334,  2015,  1010,\n",
       "          3048,  2006,  2416,  7787,  1012,   102],\n",
       "        [  101,  2028, 14433,  2003, 10140,   102,  1037,  2210,  4937,\n",
       "          2003,  3492,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]], dtype=int32)>,\n",
       " 'input_mask': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_train \n",
    "# input_word_ids就是tokenized之后的文本\n",
    "# input mask用来指定谁是padding\n",
    "# input_type_ids用来指定谁是文本1谁是文本2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_word_ids  shape: (2, 33)\n",
      "input_mask      shape: (2, 33)\n",
      "input_type_ids  shape: (2, 33)\n",
      "glue_train_labels shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "for key, value in glue_train.items():\n",
    "  print(f'{key:15s} shape: {value.shape}')\n",
    "\n",
    "print(f'glue_train_labels shape: {glue_train_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 30522}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
    "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
    "\n",
    "bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
    "\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier, bert_encoder = bert.bert_models.classifier_model(\n",
    "    bert_config, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_classifier\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_type_ids (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_encoder_1 (BertEncoder)    [(None, None, 768),  109482240   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 input_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           bert_encoder_1[0][1]             \n",
      "__________________________________________________________________________________________________\n",
      "sentence_prediction (Classifica (None, 2)            1538        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(bert_classifier, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14801878, -0.11110532],\n",
       "       [ 0.05599343, -0.06263569]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_batch = {key: val[:10] for key, val in glue_train.items()}\n",
    "\n",
    "bert_classifier(\n",
    "    glue_batch, training=True\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[  101,  1996,  7235,  9819,  2097,  2552,  2004, 20478, 21334,\n",
       "          2015,  1010,  6575,  2005,  3350,  1997,  2627,  2300,  1012,\n",
       "           102,  1996,  9819,  2552,  2004, 20478, 21334,  2015,  1010,\n",
       "          3048,  2006,  2416,  7787,  1012,   102],\n",
       "        [  101,  2028, 14433,  2003, 10140,   102,  1037,  2210,  4937,\n",
       "          2003,  3492,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]], dtype=int32)>,\n",
       " 'input_mask': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(2, 33), dtype=int32, numpy=\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后看明白模型的结构就可以了\n",
    "# transformer encoding的第一个?指batch_size，第二个?指的是seq_len\n",
    "# 那些个transformer是啥就没看了，不重要，可以看paper去"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}