{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n",
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "seed=42\n",
    "raw_train_ds=tf.keras.preprocessing.text_dataset_from_directory(\"Stack Overflow dataset/train\",batch_size=batch_size,\n",
    "                                                                validation_split=0.2,\n",
    "                                                                subset='training',\n",
    "                                                                seed=seed)\n",
    "raw_val_ds=tf.keras.preprocessing.text_dataset_from_directory(\"Stack Overflow dataset/train\",batch_size=batch_size,\n",
    "                                                             validation_split=0.2,\n",
    "                                                             subset='validation',\n",
    "                                                             seed=seed)\n",
    "raw_test_ds=tf.keras.preprocessing.text_dataset_from_directory('Stack Overflow dataset/test',batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "def custom_standardization(input_data):\n",
    "#     print(input_data)\n",
    "    input_data=tf.strings.lower(input_data)\n",
    "    input_data=tf.strings.regex_replace(input_data,'<br>',' ')\n",
    "    input_data=tf.strings.regex_replace(input_data,'[%s]'%re.escape(string.punctuation),'')\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens=10000\n",
    "seq_max_len=250\n",
    "vectorization_layer=TextVectorization(standardize=custom_standardization,max_tokens=max_tokens,\n",
    "                                     output_mode='int',output_sequence_length=seq_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_text=raw_train_ds.map(lambda x,y:x)\n",
    "vectorization_layer.adapt(raw_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b'\"why do both blank objects return the same data i have created 2 objects of the class gconveyor. i want to get some data about the objects when i select them, but both return the same information. thanks for the help!../* .* file: dragobjects.blank  .*/ .import acm.graphics.*; .import acm.program.*; .import blank.awt.event.*;..public class dragobjects extends graphicsprogram { .private static final long serialversionuid = 1l;.// initializes the program .public void init() { .    //adding a few test objects.    gconveyor conv = new gconveyor(50, 44, 120); .    add(conv); .    gconveyor conv2 = new gconveyor(30, 24, 60); .    add(conv2); ..    addmouselisteners(); .    addkeylisteners(); .    } ..// called on mouse press to record the coordinates of the click */ .public void mousepressed(mouseevent e) { .    // gpoint has x and y coordinate .    last = new gpoint(e.getpoint()); .    gobj = getelementat(last);  .    //looking at stuff so to understand.    getobjectdata ();.}...public void getobjectdata (){.    //looking at stuff so to understand.    system.out.println(gobj.tostring());    ..    gcontainer oblength = gobj.getparent();.    system.out.println(oblength.tostring());    ..    int d = ((gcompound) gobj).getelementcount();.    system.out.println( \"\"element per gconveyor:\"\"+ d  );..    system.out.println( \"\"hashcode:\"\" +gobj.hashcode());..    int y = this.getelementcount();.    system.out.println( \"\"this element count:\"\"+ y  );..    int a = gconveyor.getbf();      .    system.out.println( \"\"bf:\"\" + a  );.    int b = gconveyor.getef();      .    system.out.println( \"\"ef:\"\" + b  );.    int h = gconveyor.getlength();      .    system.out.println( \"\"length:\"\" + h  );.    int c = ((gconveyor) gobj).getlength();     .    system.out.println( \"\"length:\"\" + c  );       .}....// called on mouse drag to reposition the object .public void mousedragged(mouseevent e) { .    if (gobj != null) { .        gobj.move(e.getx() - last.getx(), e.gety() - last.gety()); .        last = new gpoint(e.getpoint());.        } } ../* private instance variables */.private gobject gobj; ./* the object being dragged */.private gpoint last; ..}...the following is my gconveyor class.. /* . * . * file: gconveyor.blank * this class implements a conveyor as a gcompound.. */ ..import blank.awt.color;.import acm.graphics.*; ..public class gconveyor extends gcompound {./* constants specifying frame size*/.private static final int frame_width = 2;.private static int mybf;.private static int myef;.private static int mylength;..private static final double scale = 10;./* private instance variables */.private grect outer;.private grect chain_box;.private grect effwidth;.private gpolygon pti;.private gpolygon pto;..public gconveyor(int bf, int ef, int length) {.outer = new grect(length, ((frame_width *2) + bf));.chain_box = new grect(length , bf - ef);.effwidth = new grect(length, bf);.pti = createanchor(scale);.pto = createanchor(scale);.add(outer, 0 , 0);.add(chain_box, 0 , frame_width);.add(effwidth, 0 , frame_width);.add(pti, 0 , frame_width + (bf-ef) + (ef/2));.add(pto, length , frame_width + (bf-ef) + (ef/2));..mybf = bf;.myef = ef;.mylength = length;..}..public static int getbf(){.return mybf;.}.public static int getef(){.return myef; .}.public static int getlength(){.return mylength;.}.../* creates a hex for the anchor */.private gpolygon createanchor(double scale) {.gpolygon poly = new gpolygon();.poly.addvertex(-0.25*scale, 0.433*scale);.poly.addvertex(-0.5*scale, 0.0*scale);.poly.addvertex(-0.25*scale, -0.433*scale);.poly.addvertex(0.25*scale, -0.433*scale);.poly.addvertex(0.5*scale, 0.0*scale);.poly.addvertex(0.25*scale, 0.433*scale);.poly.setfilled(true);.poly.setfillcolor(color.blue);.return poly;.}..public string tostring(){.return(\"\"\"\" +mybf+ +myef+ +mylength+ \"\"\"\");..}..}\"\\n', shape=(), dtype=string)\n",
      "Label java\n",
      "tf.Tensor(b'\"why do both blank objects return the same data i have created 2 objects of the class gconveyor. i want to get some data about the objects when i select them, but both return the same information. thanks for the help!../* .* file: dragobjects.blank  .*/ .import acm.graphics.*; .import acm.program.*; .import blank.awt.event.*;..public class dragobjects extends graphicsprogram { .private static final long serialversionuid = 1l;.// initializes the program .public void init() { .    //adding a few test objects.    gconveyor conv = new gconveyor(50, 44, 120); .    add(conv); .    gconveyor conv2 = new gconveyor(30, 24, 60); .    add(conv2); ..    addmouselisteners(); .    addkeylisteners(); .    } ..// called on mouse press to record the coordinates of the click */ .public void mousepressed(mouseevent e) { .    // gpoint has x and y coordinate .    last = new gpoint(e.getpoint()); .    gobj = getelementat(last);  .    //looking at stuff so to understand.    getobjectdata ();.}...public void getobjectdata (){.    //looking at stuff so to understand.    system.out.println(gobj.tostring());    ..    gcontainer oblength = gobj.getparent();.    system.out.println(oblength.tostring());    ..    int d = ((gcompound) gobj).getelementcount();.    system.out.println( \"\"element per gconveyor:\"\"+ d  );..    system.out.println( \"\"hashcode:\"\" +gobj.hashcode());..    int y = this.getelementcount();.    system.out.println( \"\"this element count:\"\"+ y  );..    int a = gconveyor.getbf();      .    system.out.println( \"\"bf:\"\" + a  );.    int b = gconveyor.getef();      .    system.out.println( \"\"ef:\"\" + b  );.    int h = gconveyor.getlength();      .    system.out.println( \"\"length:\"\" + h  );.    int c = ((gconveyor) gobj).getlength();     .    system.out.println( \"\"length:\"\" + c  );       .}....// called on mouse drag to reposition the object .public void mousedragged(mouseevent e) { .    if (gobj != null) { .        gobj.move(e.getx() - last.getx(), e.gety() - last.gety()); .        last = new gpoint(e.getpoint());.        } } ../* private instance variables */.private gobject gobj; ./* the object being dragged */.private gpoint last; ..}...the following is my gconveyor class.. /* . * . * file: gconveyor.blank * this class implements a conveyor as a gcompound.. */ ..import blank.awt.color;.import acm.graphics.*; ..public class gconveyor extends gcompound {./* constants specifying frame size*/.private static final int frame_width = 2;.private static int mybf;.private static int myef;.private static int mylength;..private static final double scale = 10;./* private instance variables */.private grect outer;.private grect chain_box;.private grect effwidth;.private gpolygon pti;.private gpolygon pto;..public gconveyor(int bf, int ef, int length) {.outer = new grect(length, ((frame_width *2) + bf));.chain_box = new grect(length , bf - ef);.effwidth = new grect(length, bf);.pti = createanchor(scale);.pto = createanchor(scale);.add(outer, 0 , 0);.add(chain_box, 0 , frame_width);.add(effwidth, 0 , frame_width);.add(pti, 0 , frame_width + (bf-ef) + (ef/2));.add(pto, length , frame_width + (bf-ef) + (ef/2));..mybf = bf;.myef = ef;.mylength = length;..}..public static int getbf(){.return mybf;.}.public static int getef(){.return myef; .}.public static int getlength(){.return mylength;.}.../* creates a hex for the anchor */.private gpolygon createanchor(double scale) {.gpolygon poly = new gpolygon();.poly.addvertex(-0.25*scale, 0.433*scale);.poly.addvertex(-0.5*scale, 0.0*scale);.poly.addvertex(-0.25*scale, -0.433*scale);.poly.addvertex(0.25*scale, -0.433*scale);.poly.addvertex(0.5*scale, 0.0*scale);.poly.addvertex(0.25*scale, 0.433*scale);.poly.setfilled(true);.poly.setfillcolor(color.blue);.return poly;.}..public string tostring(){.return(\"\"\"\" +mybf+ +myef+ +mylength+ \"\"\"\");..}..}\"\\n', shape=(), dtype=string)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: text_vectorization_3/strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-65-1584f8c6147c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Review\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfirst_review\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Label\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_train_ds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclass_names\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfirst_label\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Vectorized review\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvectorize_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfirst_review\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfirst_label\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-65-1584f8c6147c>\u001B[0m in \u001B[0;36mvectorize_text\u001B[0;34m(text, label)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m#     text = tf.expand_dims(text, -1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#     print(text)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mvectorization_layer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;31m# retrieve a batch (of 32 reviews and labels) from the dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mtext_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_train_ds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 985\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    986\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    987\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    589\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdense_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m         \u001B[0msequence_len\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdense_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    592\u001B[0m         \u001B[0mpad_amt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output_sequence_length\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0msequence_len\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m         \u001B[0mpad_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdense_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpad_amt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36m_slice_helper\u001B[0;34m(tensor, slice_spec, var)\u001B[0m\n\u001B[1;32m   1022\u001B[0m         \u001B[0mellipsis_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mellipsis_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1023\u001B[0m         \u001B[0mvar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1024\u001B[0;31m         name=name)\n\u001B[0m\u001B[1;32m   1025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1026\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001B[0m\n\u001B[1;32m   1194\u001B[0m       \u001B[0mellipsis_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mellipsis_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1195\u001B[0m       \u001B[0mnew_axis_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnew_axis_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1196\u001B[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001B[0m\u001B[1;32m   1197\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1198\u001B[0m   \u001B[0mparent_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001B[0m in \u001B[0;36mstrided_slice\u001B[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001B[0m\n\u001B[1;32m  10318\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10319\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 10320\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  10321\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  10322\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6841\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6842\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6843\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6844\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6845\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: text_vectorization_3/strided_slice/"
     ]
    }
   ],
   "source": [
    "def vectorize_text(text, label):\n",
    "    print(text)\n",
    "#     text = tf.expand_dims(text, -1)\n",
    "#     print(text)\n",
    "    return vectorization_layer(text), label\n",
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review,first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(None,), dtype=string)\n",
      "Tensor(\"args_0:0\", shape=(None,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = raw_train_ds.map(lambda text_b,label_b:(vectorization_layer(text_b),label_b))\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 250), (None,)), types: (tf.int64, tf.int32)>\n",
      "(32, 250)\n",
      "tf.Tensor(\n",
      "[2137  187   19    6   94    9 1876   12 1283   19   21  319   19   24\n",
      "    4  478   11    3   34  152   13   65 2137  187   19    6   94    9\n",
      " 1876   12 1283   19   21  319    1    6    2  976 1948   36 7449 1596\n",
      "   36    1    1    1    1 8564    1    1    1   27    1    1 2242    9\n",
      "    2 1558    6    1    1 2242    9    2 2248    6    1    1   58  104\n",
      "   74   24    4  478   11    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  24    4   41 1464   21    5 1011  983    3   34   81    4  124    5\n",
      " 1940  244  132    3   17    1 9202    8    2 1940 1463   79  324   59\n",
      "   89    8  164 1283   79  210   13    3   17  265    5 1166   14   95\n",
      "  983    9  324   59   89    8  164 1283    3   46    4 1104 3830    5\n",
      " 2003   59    2 9202   26    3   46    2  379    8  396    4   33    7\n",
      " 1166   50   11   90 3830   59 1628    9  324   19  324  782  584 1378\n",
      "    1   35   70    1    4   41  427   26    3  166  366   11 1011    1\n",
      "  227   13  159   66    6  804   55    3  912   26    2  299    6   12\n",
      "    1  364    1   38   21  983    1    6   24    3 2037    2    1    1\n",
      "    1    1   10    1   19    1   49    1    1    6   32  652    9 2794\n",
      "   14 5223   36   11    1 2005    8    3   46   93    2  905    4 5238\n",
      "    2    1    6    5 1472   14    1   59  247    1  101    6   24    3\n",
      "  186   10  201  766    7    1    1    1  143    1    1    1  428   23\n",
      " 1940  325    2 2005   26    2   89    8  164  337  129 1721  638 2296\n",
      "    3 3830 2005 1393   59    2 1166  321    1   45  584    1   67  157\n",
      " 1656   45  247   21 1011  983   45   83  144  159   14    3  900  148\n",
      "  101   59 1982   14   35  104   74    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(val_ds)\n",
    "for text_batch,label_batch in val_ds.take(1):\n",
    "    print(text_batch.shape)\n",
    "    for i in range(2):\n",
    "        print(text_batch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((None, 250), (None,)), types: (tf.int64, tf.int32)>\n",
      "(32, 250)\n",
      "tf.Tensor(\n",
      "[  16   18 1299  159    3   34   81    4  107    5 1299   12    5    1\n",
      "    1    3   17    5 2454  415    7   23  153  279  415   24   40    3\n",
      "  301  202 1406    1  196   15    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 441   63   79 2366   50    3  227    5  114    7   32 1726  166  148\n",
      "    2  461   45  142   17    2  299   14  912    2  127  159  283   83\n",
      "   99   80  441  510   79 4484    2  127    6    2    1    1 4004 2366\n",
      " 1064    1 9018   16 7453   16 4517 2919    1  126   16 1064 9018 7453\n",
      " 4517 1064 7453 1226 1064 2919    1  299   95   93  215  235    4  741\n",
      "    2 2366   31    2  510   26    3  166  475    4  148    5   84    4\n",
      "  536    2  510   21    2    1   80 4004 2366 1064   16 4517 1226 9018\n",
      "   16 7453   16 4517    1    1  300   80    1  115  948    9   47    2\n",
      " 1070 1185    4  536   26  900 2271  592  124    5  596    4  384  872\n",
      "  197  214  135  300    1   15  596  300 2366    1   12  300    3   19\n",
      "    3   62    1    3   10  596  178   17    2 4484   36    5  214  125\n",
      " 4484   10    1   82    9  457   14   17    2 4484    1    1   58  189\n",
      "    3  115  417   59  895 2004   26  166  475    4 5133    5 1706   84\n",
      "    4 1192    2   80  299  178   17    4  478    2  114   52  106  681\n",
      "    8  166  148   23   84    4    2 1912   77    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(250,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(val_ds)\n",
    "for text_batch,label_batch in train_ds.take(1):\n",
    "    print(text_batch.shape)\n",
    "    for i in range(2):\n",
    "        print(text_batch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_TUNE=tf.data.experimental.AUTOTUNE\n",
    "train_ds=train_ds.cache().prefetch(buffer_size=AUTO_TUNE)\n",
    "val_ds=val_ds.cache().prefetch(buffer_size=AUTO_TUNE)\n",
    "train_ds=test_ds.cache().prefetch(buffer_size=AUTO_TUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    layers.Embedding(max_tokens+1,embed_dim),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer='adam',\n",
    "             metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.3713 - sparse_categorical_accuracy: 0.3616 - val_loss: 1.3460 - val_sparse_categorical_accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3070 - sparse_categorical_accuracy: 0.5209 - val_loss: 1.2506 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1888 - sparse_categorical_accuracy: 0.6177 - val_loss: 1.1168 - val_sparse_categorical_accuracy: 0.6463\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0541 - sparse_categorical_accuracy: 0.6900 - val_loss: 0.9920 - val_sparse_categorical_accuracy: 0.7056\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9385 - sparse_categorical_accuracy: 0.7334 - val_loss: 0.8918 - val_sparse_categorical_accuracy: 0.7444\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8429 - sparse_categorical_accuracy: 0.7610 - val_loss: 0.8135 - val_sparse_categorical_accuracy: 0.7613\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7644 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.7525 - val_sparse_categorical_accuracy: 0.7681\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7035 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6502 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.6663 - val_sparse_categorical_accuracy: 0.7856\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6063 - sparse_categorical_accuracy: 0.8256 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.7937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda247a6080>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=10\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.8301\n",
      "Loss:  0.5744057893753052\n",
      "Accuracy:  0.8301249742507935\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 250), (None,)), types: (tf.int64, tf.int32)>\n",
      "(32, 250)\n",
      "tf.Tensor(\n",
      "[[ 1.01864910e+00  2.72390938e+00 -2.67486960e-01 -2.90631390e+00]\n",
      " [-2.33068883e-01  5.73790908e-01 -3.83996034e+00  3.86428952e+00]\n",
      " [ 1.91842496e+00  5.93332672e+00 -4.23278904e+00 -2.69860911e+00]\n",
      " [-3.01611602e-01 -7.17531204e-01  1.40938270e+00 -4.17184591e-01]\n",
      " [ 3.27298999e+00  1.73807287e+00 -2.99554133e+00 -1.50769317e+00]\n",
      " [ 4.77523133e-02 -2.93913305e-01  5.65608144e-01 -3.66838753e-01]\n",
      " [ 9.67699349e-01 -1.03487074e-01 -1.42177179e-01 -6.83586299e-01]\n",
      " [-4.49122190e-01 -1.26241887e+00  2.83325601e+00 -1.00161743e+00]\n",
      " [-5.51959217e-01 -5.82003534e-01  1.39206052e+00 -1.88537061e-01]\n",
      " [-3.97035837e-01 -9.40023541e-01  1.24123359e+00  3.52846533e-02]\n",
      " [ 1.09772682e+00  1.98007441e+00 -3.32152456e-01 -2.24560237e+00]\n",
      " [ 1.92769969e+00  1.36691415e+00 -2.01583934e+00 -9.43649232e-01]\n",
      " [-7.74196208e-01 -6.26803279e-01  2.90414602e-01  1.01825857e+00]\n",
      " [ 2.16854244e-01  2.09291190e-01  2.68480867e-01 -5.94823778e-01]\n",
      " [ 7.87852407e-02 -2.46847227e-01 -2.75316983e-01  4.40460861e-01]\n",
      " [-2.66759205e+00 -1.48081374e+00 -1.38819742e+00  5.62465143e+00]\n",
      " [ 2.03519128e-03 -4.23799247e-01  2.52986968e-01  9.31264237e-02]\n",
      " [-1.18633306e+00 -1.50097334e+00 -4.58676100e-01  3.14298940e+00]\n",
      " [-8.71268272e-01 -1.59724760e+00 -4.56890821e-01  2.84333110e+00]\n",
      " [ 4.27684486e-01 -4.43637758e-01  1.06064379e+00 -9.59950030e-01]\n",
      " [-2.75699198e-01 -2.69962341e-01  3.83224040e-01  1.82149798e-01]\n",
      " [ 9.32142735e-02 -4.14460063e-01  7.88084149e-01 -4.81526971e-01]\n",
      " [-3.35781664e-01 -7.44202614e-01  1.03267229e+00  3.66240665e-02]\n",
      " [-3.80163118e-02  1.81751456e-02  3.60160828e-01 -3.96091223e-01]\n",
      " [ 1.28281558e+00  3.17910147e+00 -2.11430931e+00 -1.86980474e+00]\n",
      " [-2.03408152e-01 -2.22056746e-01  2.54157275e-01  1.07109152e-01]\n",
      " [ 8.66405666e-01 -7.81101584e-02  9.13358688e-01 -1.43301618e+00]\n",
      " [-6.29762411e-01 -8.85060251e-01 -4.54554349e-01  1.89831173e+00]\n",
      " [ 1.50777787e-01  2.57384092e-01 -5.95013916e-01  2.94021547e-01]\n",
      " [ 1.08806288e+00  3.68365318e-01 -5.18200517e-01 -7.64665425e-01]\n",
      " [-9.87955570e-01 -8.01575422e-01 -2.01631077e-02  1.77391005e+00]\n",
      " [-8.97441268e-01 -1.51850581e+00  2.62134719e+00 -6.42033592e-02]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(val_ds)\n",
    "for text_batch,label_batch in train_ds.take(1):\n",
    "    print(text_batch.shape)\n",
    "    print(model(text_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model=tf.keras.Sequential([\n",
    "    vectorization_layer,\n",
    "    model,\n",
    "    layers.Softmax()\n",
    "])\n",
    "\n",
    "export_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5744 - acc: 0.8301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.574406087398529, 0.8301249742507935]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_model.evaluate(raw_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.66239583e-01 2.50389189e-01 2.06916839e-01 2.76454419e-01]\n",
      " [2.02704877e-01 1.93109617e-01 4.43809986e-01 1.60375550e-01]\n",
      " [6.43859152e-03 1.49128342e-03 9.17588994e-02 9.00311172e-01]\n",
      " [3.81393254e-01 3.51416081e-01 1.51539415e-01 1.15651362e-01]\n",
      " [2.65290961e-02 2.84586251e-02 9.11056325e-02 8.53906631e-01]\n",
      " [1.76378518e-01 1.43474624e-01 5.59315205e-01 1.20831653e-01]\n",
      " [5.48055470e-02 1.51517112e-02 9.08744335e-01 2.12983508e-02]\n",
      " [1.29221395e-01 4.33349870e-02 1.06597267e-01 7.20846355e-01]\n",
      " [1.19641997e-01 1.20060198e-01 2.33394261e-02 7.36958325e-01]\n",
      " [2.00306237e-01 7.98141837e-01 2.95649777e-04 1.25627313e-03]\n",
      " [8.28096494e-02 6.00787587e-02 6.37680292e-01 2.19431236e-01]\n",
      " [3.94126356e-01 1.53263047e-01 4.13073123e-01 3.95375043e-02]\n",
      " [2.78474331e-01 1.22255348e-01 5.72461784e-01 2.68085226e-02]\n",
      " [2.30965856e-02 1.00192586e-02 2.71148272e-02 9.39769268e-01]\n",
      " [8.73269200e-01 1.01383224e-01 1.08123086e-02 1.45353442e-02]\n",
      " [2.76805848e-01 3.09144437e-01 1.13467500e-01 3.00582230e-01]\n",
      " [1.29239187e-01 1.01919755e-01 6.44155324e-01 1.24685727e-01]\n",
      " [4.24949656e-04 8.50068347e-04 1.73593464e-04 9.98551428e-01]\n",
      " [3.33701402e-01 3.78235966e-01 1.47202298e-01 1.40860304e-01]\n",
      " [1.62086651e-01 7.58614242e-02 7.46662021e-01 1.53899426e-02]\n",
      " [6.99105561e-01 1.78153008e-01 6.75799549e-02 5.51614873e-02]\n",
      " [1.81187823e-01 1.82230264e-01 3.50183576e-01 2.86398232e-01]\n",
      " [6.40135109e-02 9.00721643e-03 9.15136814e-01 1.18425013e-02]\n",
      " [2.35519737e-01 2.49132812e-01 3.50714266e-01 1.64633170e-01]\n",
      " [3.49487364e-01 4.19188857e-01 1.96503595e-01 3.48200910e-02]\n",
      " [2.23641053e-01 1.70476183e-01 3.24950606e-01 2.80932099e-01]\n",
      " [4.24342812e-04 7.50774576e-04 8.06503813e-05 9.98744249e-01]\n",
      " [2.56268084e-01 5.75363457e-01 8.21219534e-02 8.62464532e-02]\n",
      " [3.88692915e-01 5.54105103e-01 1.94684379e-02 3.77334803e-02]\n",
      " [7.86911249e-02 9.19745088e-01 7.09271117e-04 8.54460639e-04]\n",
      " [8.73833477e-01 4.83119935e-02 9.94761195e-03 6.79069832e-02]\n",
      " [5.36479354e-01 1.83798790e-01 1.76823422e-01 1.02898434e-01]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for text_batch,label_batch in raw_test_ds.take(1):\n",
    "    print(export_model(text_batch))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'string'>\n",
      "(32,)\n",
      "tf.Tensor(\n",
      "[[1.73028529e-01 1.22906744e-01 4.73713636e-01 2.30351105e-01]\n",
      " [1.29243761e-01 8.60906720e-01 4.32570605e-03 5.52387629e-03]\n",
      " [1.23685069e-01 8.15991461e-02 6.84530258e-01 1.10185534e-01]\n",
      " [2.05235809e-01 1.43402711e-01 5.28464973e-01 1.22896567e-01]\n",
      " [2.32805401e-01 2.39914507e-01 2.97490805e-01 2.29789242e-01]\n",
      " [8.53178948e-02 9.83647704e-02 3.17718953e-01 4.98598456e-01]\n",
      " [5.87741919e-02 1.17429644e-01 7.40262717e-02 7.49769866e-01]\n",
      " [8.28096494e-02 6.00787587e-02 6.37680292e-01 2.19431236e-01]\n",
      " [3.95798206e-01 5.23534656e-01 4.48908024e-02 3.57763618e-02]\n",
      " [4.24949656e-04 8.50068347e-04 1.73593464e-04 9.98551428e-01]\n",
      " [2.70912915e-01 6.54679000e-01 6.48397133e-02 9.56842396e-03]\n",
      " [1.90475494e-01 3.33747983e-01 3.33693296e-01 1.42083183e-01]\n",
      " [4.33768630e-01 1.94838479e-01 2.58717090e-01 1.12675764e-01]\n",
      " [2.38250405e-01 2.69958287e-01 2.16378525e-01 2.75412738e-01]\n",
      " [8.73269200e-01 1.01383224e-01 1.08123086e-02 1.45353442e-02]\n",
      " [5.36999106e-01 4.29962516e-01 5.69561450e-03 2.73428075e-02]\n",
      " [1.34900091e-02 2.61787232e-03 9.70982492e-01 1.29095875e-02]\n",
      " [7.96200484e-02 7.86087438e-02 3.63232762e-01 4.78538454e-01]\n",
      " [6.99105561e-01 1.78153008e-01 6.75799549e-02 5.51614873e-02]\n",
      " [1.68445304e-01 1.23141386e-01 6.50416136e-01 5.79971969e-02]\n",
      " [2.46936709e-01 1.75469697e-01 4.14464712e-01 1.63128942e-01]\n",
      " [1.81306869e-01 6.04989901e-02 7.43182182e-01 1.50119402e-02]\n",
      " [3.81422937e-01 2.18463838e-01 2.17162445e-01 1.82950795e-01]\n",
      " [6.26486093e-02 2.95459423e-02 8.60101700e-01 4.77037355e-02]\n",
      " [1.81187823e-01 1.82230264e-01 3.50183576e-01 2.86398232e-01]\n",
      " [2.05815043e-02 2.97582466e-02 1.30986378e-01 8.18673849e-01]\n",
      " [3.68631124e-01 1.36179283e-01 1.04673170e-01 3.90516400e-01]\n",
      " [2.82225180e-02 1.56028168e-02 1.07527353e-01 8.48647296e-01]\n",
      " [8.04878294e-01 1.55132979e-01 3.00487224e-02 9.94003844e-03]\n",
      " [4.56752121e-01 3.47255915e-01 1.39766231e-01 5.62257692e-02]\n",
      " [2.78320193e-01 4.86913562e-01 3.67432833e-02 1.98022991e-01]\n",
      " [8.04247737e-01 7.51022026e-02 4.92816977e-02 7.13683888e-02]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "only_text=raw_test_ds.map(lambda x,y:x)\n",
    "for text_batch in only_text.take(1):\n",
    "    print(text_batch.dtype)\n",
    "    print(text_batch.shape)\n",
    "    print(export_model(text_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tensorflow.python.data.ops.dataset_ops.MapDataset'> input: <MapDataset shapes: (None,), types: tf.string>\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<MapDataset shapes: (None,), types: tf.string>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-100-6bc4f1b07ee7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 综上可知，model可以接受的是tensor，但不能直接接受dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mexport_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0monly_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 985\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    986\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    987\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    370\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_graph_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m  \u001B[0;31m# handle the corner case where self.layers is empty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    384\u001B[0m     \"\"\"\n\u001B[1;32m    385\u001B[0m     return self._run_internal_graph(\n\u001B[0;32m--> 386\u001B[0;31m         inputs, training=training, mask=mask)\n\u001B[0m\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mcompute_output_shape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    488\u001B[0m     \u001B[0mtensor_usage_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tensor_usage_count\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 490\u001B[0;31m       \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conform_to_reference_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mref_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    491\u001B[0m       \u001B[0mx_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m       \u001B[0mtensor_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx_id\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mtensor_usage_count\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36m_conform_to_reference_input\u001B[0;34m(self, tensor, ref_input)\u001B[0m\n\u001B[1;32m    591\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcomposite_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCompositeTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m       \u001B[0;31m# Dtype casting.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 593\u001B[0;31m       \u001B[0mtensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mref_input\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    594\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mcast\u001B[0;34m(x, dtype, name)\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    920\u001B[0m       \u001B[0;31m# strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 921\u001B[0;31m       \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    922\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_dtype\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    923\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbase_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1497\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1498\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1499\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1500\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1501\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    336\u001B[0m                                          as_ref=False):\n\u001B[1;32m    337\u001B[0m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 338\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    339\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    262\u001B[0m   \"\"\"\n\u001B[1;32m    263\u001B[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0;32m--> 264\u001B[0;31m                         allow_broadcast=True)\n\u001B[0m\u001B[1;32m    265\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    273\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tf.constant\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    274\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 275\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    276\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_constant_eager_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m   \u001B[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 300\u001B[0;31m   \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    301\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     96\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Attempt to convert a value (<MapDataset shapes: (None,), types: tf.string>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "\n",
    "# 综上可知，model可以接受的是可以直接喂给模型的tensor，例如\n",
    "# export_model的入口是vectorization_layer，\n",
    "# 那么export_mode接受的就是一个Tensor，这个tensor是一个batch的文字，类型是str， shape=(32,), dtype=string\n",
    "# 但不能直接接受only_text，因为他是一个dataset，他持有的每一个元素都是一个batch，也就是说他持有了多个batch\n",
    "export_model(only_text) #报错，而evaluate可以接受dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}